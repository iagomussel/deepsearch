
# üîç DeepSearch

Sistema avan√ßado de pesquisa profunda que combina **LLMs locais**, **busca web inteligente** e **indexa√ß√£o vetorial** para gerar relat√≥rios detalhados e contextualizados.

## ‚ú® Caracter√≠sticas

- ü§ñ **LLMs Locais**: Ollama com Gemma2, Llama3.1 e modelos de embedding
- üåê **Busca Web Avan√ßada**: DuckDuckGo com dorks e scraping inteligente  
- üóÑÔ∏è **Vector Database**: PostgreSQL + pgvector para indexa√ß√£o sem√¢ntica
- üìä **Relat√≥rios Inteligentes**: Gera√ß√£o autom√°tica de markdown estruturado
- üõ°Ô∏è **Ferramentas Seguras**: Web-search, fetch e shell com controles de seguran√ßa
- üîå **API REST**: Interface HTTP completa para integra√ß√µes
- üíª **CLI Interativo**: Interface de linha de comando rica e intuitiva

## üöÄ In√≠cio R√°pido

### Pr√©-requisitos
- Node.js 18+
- Docker & Docker Compose
- 8GB+ RAM (para modelos LLM)

### Instala√ß√£o

```bash
# Clone e setup
git clone <repo-url> deepsearch
cd deepsearch
make setup

# Inicia servi√ßos
make start

# Primeira pesquisa
node index.js "intelig√™ncia artificial"
```

## üéØ Uso Esperado

```bash
$ node index.js "fa√ßa uma pesquisa sobre harmoniza√ß√£o sonora"

üîç Iniciando busca profunda para: "fa√ßa uma pesquisa sobre harmoniza√ß√£o sonora"

‚úÖ LLM local conectado
‚úì Gerados 8 termos de busca
‚úì Pesquisando em 32 sites...
‚úì An√°lise conclu√≠da
‚úÖ Relat√≥rio pronto: "F:\deepsearch\reports\20240920_1430_harmonizacao_sonora.md"

ü§ñ Modo interativo iniciado

Digite suas sugest√µes ou \q para encerrar
:> 
```

## üìÅ Estrutura do Projeto

```
deepsearch/
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ api/           # API HTTP Express
‚îÇ   ‚îú‚îÄ‚îÄ services/      # Servi√ßos core (LLM, Web, DB)
‚îÇ   ‚îú‚îÄ‚îÄ tools/         # Ferramentas seguras
‚îÇ   ‚îî‚îÄ‚îÄ utils/         # Utilit√°rios (logger, etc)
‚îú‚îÄ‚îÄ docker/            # Configura√ß√µes Docker
‚îú‚îÄ‚îÄ config/            # Configura√ß√µes da aplica√ß√£o
‚îú‚îÄ‚îÄ scripts/           # Scripts de setup e manuten√ß√£o
‚îú‚îÄ‚îÄ reports/           # Relat√≥rios gerados
‚îú‚îÄ‚îÄ logs/              # Logs da aplica√ß√£o
‚îú‚îÄ‚îÄ index.js           # CLI principal
‚îú‚îÄ‚îÄ Makefile           # Comandos do projeto
‚îî‚îÄ‚îÄ docker-compose.yml # Orquestra√ß√£o de containers
```

## üõ†Ô∏è Comandos Principais

```bash
# Setup e Instala√ß√£o
make setup              # Configura√ß√£o inicial completa
make install            # Instala depend√™ncias Node.js

# Controle de Servi√ßos  
make start              # Inicia todos os servi√ßos
make stop               # Para todos os servi√ßos
make restart            # Reinicia servi√ßos
make status             # Status dos containers

# Desenvolvimento
make start-dev          # Modo desenvolvimento (sem API container)
make logs               # Logs em tempo real
make health             # Verifica sa√∫de dos servi√ßos

# Modelos LLM
make models-pull        # Baixa modelos espec√≠ficos
make models-list        # Lista modelos instalados

# Manuten√ß√£o
make clean              # Limpa containers e volumes
make backup             # Backup do banco de dados
make stats              # Estat√≠sticas do sistema
```

## üì° API REST

A API REST est√° dispon√≠vel em `http://localhost:3000` com os seguintes endpoints:

### Principais Endpoints

```bash
# Health check
GET /health

# Busca profunda
POST /api/search
{
  "query": "sua pesquisa aqui",
  "options": {
    "maxSources": 50,
    "useAdvancedSearch": true
  }
}

# Busca vetorial por similaridade
POST /api/vector-search
{
  "query": "termo de busca",
  "limit": 10,
  "threshold": 0.7
}

# Hist√≥rico de pesquisas
GET /api/history?limit=20

# Detalhes de uma sess√£o
GET /api/session/{sessionId}

# Modelos LLM dispon√≠veis
GET /api/models
```

### Exemplos com curl

```bash
# Busca simples
curl -X POST http://localhost:3000/api/search \
  -H "Content-Type: application/json" \
  -d '{"query": "machine learning"}'

# Hist√≥rico
curl http://localhost:3000/api/history

# Health check
curl http://localhost:3000/health
```

## üîß CLI Interativo

O CLI oferece comandos especiais no modo interativo:

```bash
:> /help        # Mostra comandos dispon√≠veis
:> /status      # Status dos servi√ßos
:> /models      # Lista modelos LLM
:> /history     # Hist√≥rico de pesquisas
:> \q           # Sair
```

## ‚öôÔ∏è Configura√ß√£o

### Vari√°veis de Ambiente (.env)

```env
# LLM Configuration
OLLAMA_BASE_URL=http://localhost:11434
DEFAULT_LLM_MODEL=llama3.1:8b
EMBEDDING_MODEL=nomic-embed-text

# API Settings
PORT=3000
API_KEY=sua-api-key-aqui

# Security
ENABLE_SHELL_TOOLS=false
ALLOWED_DOMAINS=*
BLOCKED_DOMAINS=localhost,127.0.0.1,10.*

# Performance
MAX_SEARCH_RESULTS=50
MAX_CONCURRENT_SCRAPES=5
PARALLEL_PROCESSING_LIMIT=5
```

### Modelos LLM Suportados

- **Llama 3.1** (8B, 70B) - Modelo principal para an√°lise
- **Gemma2** (2B, 9B) - Modelo alternativo r√°pido  
- **CodeLlama** (7B) - Especializado em c√≥digo
- **Nomic Embed Text** - Gera√ß√£o de embeddings

## üõ°Ô∏è Seguran√ßa

O sistema inclui v√°rias camadas de seguran√ßa:

- ‚úÖ **Valida√ß√£o de URLs** - Apenas HTTP/HTTPS
- ‚úÖ **Dom√≠nios Bloqueados** - IPs locais/privados bloqueados
- ‚úÖ **Rate Limiting** - API com limites de requisi√ß√µes
- ‚úÖ **Sanitiza√ß√£o de Comandos** - Shell tools com whitelist
- ‚úÖ **Valida√ß√£o de Paths** - Preven√ß√£o de path traversal
- ‚úÖ **Content-Type Validation** - Apenas tipos permitidos

## üìà Performance

### Otimiza√ß√µes Implementadas

- **Cache de Embeddings** - Evita reprocessamento
- **Processamento Paralelo** - Scraping concorrente
- **Indexa√ß√£o Vetorial** - Busca sem√¢ntica r√°pida
- **Rate Limiting Inteligente** - Evita bloqueios
- **Pool de Conex√µes** - PostgreSQL otimizado

### M√©tricas T√≠picas

- **Gera√ß√£o de Termos**: 2-5 segundos
- **Busca Web**: 30-60 segundos (50 sites)
- **An√°lise de Conte√∫do**: 5-10 segundos/p√°gina
- **Gera√ß√£o de Relat√≥rio**: 10-30 segundos

## üö® Troubleshooting

### Problemas Comuns

```bash
# Ollama n√£o responde
make logs-llm
docker-compose restart ollama

# PostgreSQL n√£o conecta  
make logs-db
docker-compose restart postgres

# Modelos n√£o baixam
make shell-ollama
ollama pull llama3.1:8b

# API n√£o responde
make health
make logs-api
```

### Logs e Debugging

```bash
# Logs espec√≠ficos
make logs-api           # API logs
make logs-db            # Database logs  
make logs-llm           # Ollama logs

# Debug mode
LOG_LEVEL=debug node index.js "teste"
```

## ü§ù Contribuindo

1. Fork o projeto
2. Crie uma branch: `git checkout -b feature/nova-funcionalidade`
3. Commit: `git commit -m 'Adiciona nova funcionalidade'`
4. Push: `git push origin feature/nova-funcionalidade`
5. Abra um Pull Request

## üìÑ Licen√ßa

MIT License - veja [LICENSE](LICENSE) para detalhes.

## üôè Agradecimentos

- [Ollama](https://ollama.ai/) - LLMs locais
- [pgvector](https://github.com/pgvector/pgvector) - Extens√£o vetorial PostgreSQL
- [DuckDuckGo](https://duckduckgo.com/) - Motor de busca web
- Comunidade Open Source
